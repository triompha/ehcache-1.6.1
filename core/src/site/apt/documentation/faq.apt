Frequently Asked Questions


* Does ehcache run on {JDK1.3}/{JDK1.4}?

   Older versions run on 1.3. Ehcache 1.5 runs on 1.4. Ehcache 1.6 required JDK 1.5.

* Can you use more than one instance of ehcache in a single VM?

     As of ehcache-1.2, yes. Create your CacheManager using new
    CacheManager(...) and keep hold of the reference. The singleton
    approach accessible with the getInstance(...) method is still available
    too. Remember that ehcache can supports hundreds of
    caches within one CacheManager. You would use separate CacheManagers
    where you want quite different configurations.

     The Hibernate EhCacheProvider has also been updated to support this behaviour.

* Can you use ehcache with Hibernate and outside of Hibernate at the same time?

     Yes. You use 1 instance of ehcache and 1 ehcache.xml. You configure your
    caches with Hibernate names for use by Hibernate. You can have other
    caches which you interact with directly outside of Hibernate.

     That is how I use ehcache in the original project it was developed in.
    For Hibernate we have about 80 Domain Object caches, 10
    StandardQueryCaches, 15 Domain Object Collection caches.

     We have around 5 general caches we interact with directly using
    BlockingCacheManager. We have 15 general caches we interact with
    directly using SelfPopulatingCacheManager. You can use one of those or
    you can just use CacheManager directly.

     I have updated the documentation extensively over the last few days.
    Check it out and let me know if you have any questions. See the tests
    for example code on using the caches directly. Look at
    CacheManagerTest, CacheTest and SelfPopulatingCacheTest.

* What happens when maxElementsInMemory is reached? Are the oldest items are expired when new ones come in?

     When the maximum number of elements in memory is reached, the least
    recently used ("LRU") element is removed. Used in this case means
    inserted with a put or accessed with a get.

     If the overflowToDisk cache attribute is false, the LRU Element is
     discarded. If true, it is transferred asynchronously to the DiskStore.

* Is it thread safe to modify Element values after retrieval from a Cache?

     Remember that a value in a cache element is globally accessible from
    multiple threads. It is inherently not thread safe to modify the value.
    It is safer to retrieve a value, delete the cache element and then
    reinsert the value.

     The {{{http://ehcache.sourceforge.net/javadoc/net/sf/ehcache/constructs/blocking/UpdatingCacheEntryFactory.html}UpdatingCacheEntryFactory}}
    does work by modifying the contents of values in place in the
    cache. This is outside of the core of ehcache and is targeted at
    high performance CacheEntryFactories for SelfPopulatingCaches.

* Can non-Serializable objects be stored in a cache?

     As of ehcache-1.2, they can be stored in caches with MemoryStores.

     Elements attempted to be replicated or overflowed to disk will be removed and a warning logged
      if not Serializable.

* Why is there an expiry thread for the DiskStore but not for the MemoryStore?

     Because the memory store has a fixed maximum number of
    elements, it will have a maximum memory use equal to the number of
    elements * the average size. When an element is added beyond the
    maximum size, the LRU element gets pushed into the DiskStore.

     While we could have an expiry thread to expire elements periodically,
    it is far more efficient to only check when we need to. The tradeoff is
    higher average memory use.

    The expiry thread keeps the disk store clean. There is hopefully less
     contention for the DiskStore's
    locks because commonly used values are in the MemoryStore. We mount our
    DiskStore on Linux using RAMFS so it is using OS memory. While we have
    more of this than the 2GB 32 bit process size limit it is still an
    expensive resource. The DiskStore thread keeps it under control.

     If you are concerned about cpu utilisation and locking in the
    DiskStore, you can set the diskExpiryThreadIntervalSeconds to a high
    number - say 1 day. Or you can effectively turn it off by setting the
    diskExpiryThreadIntervalSeconds to a very large value.

* What elements are mandatory in ehcache.xml?

     The documentation has been updated with comprehensive coverage of the
    schema for ehcache and all elements and attributes, including whether
    they are mandatory. See the {{{http://ehcache.sourceforge.net/documentation/#mozTocId258426}Declarative
    Configuration}} chapter.

* Can I use ehcache as a memory cache only?

     Yes. Just set the overflowToDisk attribute of cache to false.

* Can I use ehcache as a disk cache only?

     Yes. Set the maxElementsInMemory attribute of cache to 0.

     This is strongly not recommended however. The minimum recommended value
    is 1. Performance is as much as 10 times higher when to one rather than
    0. If not set to at least 1 a warning will be issued at Cache creation
    time.

* Where is the source code? The source code is distributed in the root directory of the download.

     It is called ehcache-x.x.zip. It is also available from SourceForge
    {{{http://ehcache.svn.sourceforge.net/viewvc/ehcache/}online}} or
    through {{{http://sourceforge.net/svn/?group_id=93232}SVN}}.

* How do you get statistics on an Element without affecting them?

     Use the {{{http://ehcache.sourceforge.net/javadoc/net/sf/ehcache/Cache.html#getQuiet%28java.io.Serializable%29}Cache.getQuiet()}} method. It returns an Element without updating statistics.

* How do you get WebSphere to work with ehcache?

     It has been {{{http://sourceforge.net/tracker/index.php?func=detail&amp;aid=1025128&amp;group_id=93232&amp;atid=603559}reported}}
    that IBM Websphere 5.1 running on IBM JDK1.4 requires commons-collection.jar in its classpath even though ehcache will not
    use it for JDK1.4 and JDK5. (This is for versions of ehcache lower than 1.6)

* Do you need to call CacheManager.getInstance().shutdown() when you finish with ehcache?

     Yes, it is recommended. If the JVM keeps running after you stop using
    ehcache, you should call CacheManager.getInstance().shutdown() so that
    the threads are stopped and cache memory released back to the JVM.
    Calling shutdown also insures that your persistent disk stores get
    written to disk in a consistent state and will be usable the next time
    they are used.

     If the CacheManager does not get shutdown it should not be a problem.
    There is a shutdown hook which calls the shutdown on JVM exit. This is
    explained in the documentation {{{http://ehcache.sourceforge.net/documentation/#mozTocId183156}here}}.

* Can you use ehcache after a CacheManager.shutdown()?

     Yes. When you call CacheManager.shutdown() is sets the singleton in
    CacheManager to null. If you try an use a cache after this you
    will get a CacheException.

     You need to call CacheManager.create(). It will create a brand new one
    good to go. Internally the CacheManager singleton gets set to the new
    one. So you can create and shutdown as many times as you like.

     There is a test which expliciyly confirms this behaviour. See
    CacheManagerTest#testCreateShutdownCreate()

*  I have created a new cache and its status is STATUS_UNINITIALISED. How do I initialise it?

    You need to add a newly created cache to a CacheManager before it gets intialised. Use code like the following:
 
---------------------------------
   CacheManager manager = CacheManager.create();
   Cache myCache = new Cache("testDiskOnly", 0, true, false, 5, 2);
   manager.addCache(myCache);
---------------------------------

* Is there a simple way to disable ehcache when testing?

     Yes. There is a System Property based method of disabling ehcache. If disabled no elements will be added to a cache.
     Set the property "net.sf.ehcache.disabled=true" to disable ehcache.

     This can easily be done using <<<-Dnet.sf.ehcache.disabled=true>>>> in the command line.

* How do I dynamically change Cache attributes at runtime?

    You can't but you can achieve the same result as follows:

    Cache cache = new Cache("test2", 1, true, true, 0, 0, true, 120, ...);
    cacheManager.addCache(cache);

    See the JavaDoc for the full parameters, also reproduced here:
     
    Having created the new cache, get a list of keys using cache.getKeys, then get each one and put it in the new cache.
    None of this will use much memory because the new cache element have values that reference the same data as the original cache.
    Then use cacheManager.removeCache("oldcachename") to remove the original cache.

* I get net.sf.ehcache.distribution.RemoteCacheException: Error doing put to
 remote peer. Message was: Error unmarshaling return header; nested
 exception is:
 java.net.SocketTimeoutException: Read timed out. What does this mean.

    It typically means you need to increase your socketTimeoutMillis. This is the amount of time a sender
     should wait for the call to the remote peer to complete. How long it takes depends on the network and
     the size of the Elements being replicated. 

    The configuration that controls this is the socketTimeoutMillis setting in cacheManagerPeerListenerFactory.
    120000 seems to work well for most scenarios.


---
    <cacheManagerPeerListenerFactory
            class="net.sf.ehcache.distribution.RMICacheManagerPeerListenerFactory"
            properties="hostName=fully_qualified_hostname_or_ip,
                        port=40001,
                        socketTimeoutMillis=120000"/>
---

* Should I use this directive when doing distributed caching? <cacheManagerEventListenerFactory class="" properties=""/>

    No. It is unrelated. It is for listening to changes in your local CacheManager.


* What is the minimum config to get distributed caching going?

     The minimum configuration you need to get distributed caching going is:

---
    <cacheManagerPeerProviderFactory
            class="net.sf.ehcache.distribution.RMICacheManagerPeerProviderFactory"
            properties="peerDiscovery=automatic,
                        multicastGroupAddress=230.0.0.1,
                        multicastGroupPort=4446"/>


<cacheManagerPeerListenerFactory
class="net.sf.ehcache.distribution.RMICacheManagerPeerListenerFactory"/>

---

    and then at least one cache declaration with

---
<cacheEventListenerFactory
    class="net.sf.ehcache.distribution.RMICacheReplicatorFactory"/>>>>
---

    in it. An example cache is:

---

    <cache name="sampleDistributedCache1"
           maxElementsInMemory="10"
           eternal="false"
           timeToIdleSeconds="100"
           timeToLiveSeconds="100"
           overflowToDisk="false">
        <cacheEventListenerFactory
            class="net.sf.ehcache.distribution.RMICacheReplicatorFactory"/>
    </cache>
---

    Each server in the cluster can have the same config.

* How can I see if distributed caching is working?

    You should see the listener port open on each server.

    You can use the distributed debug tool to see what is going on. (See {{http://ehcache.sourceforge.net/documentation/remotedebugger.html}}).



* Why can't I run multiple applications using ehcache on one machine?

   Because of an RMI bug, in JDKs before JDK1.5 such as JDK1.4.2, ehcache is limited to one CacheManager operating in distributed mode per virtual machine.
   (The bug limits the number of RMI registries to one per virtual machine). Because this is the expected deployment configuration, however,
    there should be no practical effect. The tell tail error is <<<java.rmi.server.ExportException: internal error: ObjID already in use>>>

    On JDK1.5 and higher it is possible to have multiple CacheManagers per VM each participating in the same or different clusters.
    Indeed the replication tests do this with 5 CacheManagers on the same VM all run from JUnit. 

* How many threads does ehcache use, and how much memory does that consume?

    The amount of memory consumed per thread is determined by the Stack Size. This is set using -Xss.
    The amount varies by OS.  It is 512KB for Linux. I tend to override the default and set it to 100kb.

    The threads are created per cache as follows:

    * DiskStore expiry thread - if DiskStore is used

    * DiskStore spool thread - if DiskStore is used

    * Replication thread - if asynchronous replication is configured.

    If you are not doing any of the above, no extra threads are created


* I am using Tomcat 5, 5.5 or 6 and I am having a problem. What can I do?

    Tomcat is such a common deployment option for applications using ehcache that there is a chapter on known
    issues and recommended practices.

    See the Using Ehcache with Tomcat chapter. ({{http://ehcache.sourceforge.net/documentation/tomcat.html}})

* I am using Java 6 and getting a java.lang.VerifyError on the Backport Concurrent classes. Why?

    The backport-concurrent library is used in ehcache to provide java.util.concurrency facilities for Java 4 - Java 6.
    Use either the Java 4 version which is compatible with Java 4-6 or use the version for your JDK.

* How do I get a memory only cache to persist to disk between VM restarts?

    While disk persistence between restarts is a feature of the DiskStore only, you can get the same behaviour for a memory only cache
    by setting up a cache with maxElementsInMemory set to Integer.MAX_VALUE, 2147483647, overflowToDisk set to true and diskPersistent set to true.


* I get a javax.servlet.ServletException: Could not initialise servlet filter when using SimplePageCachingFilter. Why?

    If you use this default implementation, the cache name is called "SimplePageCachingFilter". You need to define a cache with that
    name in ehcache.xml. If you override CachingFilter you are required to set your own cache name.
    
* I see, in my application's log:

---
WARN  CacheManager ...  Creating a new instance of CacheManager using the diskStorePath
 "C:\temp\tempcache" which is already used by an existing CacheManager.
---

  This means, that for some reason, your application is trying to create a second or more instance of Ehcache's
  CacheManager with the same configuration. Ehcache is automatically resolving the Disk path conflict,
   which works fine.

   To eliminate the warning:

   * Use a separate configuration per instance

   * If you only want one instance use the singleton creation methods i.e <<<CacheManager.getInstance()>>>.
     In Hibernate there is a special provider
     for this called <<<net.sf.ehcache.hibernate.SingletonEhCacheProvider>>>. See the Hibernate page for details.


* How do I add a CacheReplicator to a cache that already exists? The cache event listening works but it does not
  get plumbed into the peering mechanism.

    The current API does not have a CacheManager event for cache configuration change. You can however make it work
    by calling the notifyCacheAdded event.

---     
    getCache().getCacheManager().getCacheManagerEventListenerRegistry().notifyC
    acheAdded("cacheName");
---

* I am using the RemoteDebugger to monitor cluster messages but all I see is "Cache size: 0"

   If you see nothing happening, but cache operations should be going through, enable trace (LOG4J) or finest (JDK) level
   logging on <code>net.sf.ehcache.distribution</code> in the logging configuration being used by the debugger.
   A large volume of log messages will appear. The normal problem is that the CacheManager has not joined the cluster.
   Look for the list of cache peers.

   Finally, the debugger in ehcache-1.5 has been improved to provide far more information on the caches that are
   replicated and events which are occurring.


* With distributed replication on Ubuntu or Debian, I see the following warning,

---
WARN [Replication Thread] RMIAsynchronousCacheReplicator.flushReplicationQueue(324)
| Unable to send message to remote peer.
Message was: Connection refused to host: 127.0.0.1; nested exception is:

java.net.ConnectException: Connection refused

java.rmi.ConnectException: Connection refused to host: 127.0.0.1; nested exception is:

java.net.ConnectException: Connection refused
---

    This is caused by a 2008 change to the Ubuntu/Debian linux default network configuration.

    Essentially, this java call: <<<InetAddress.getLocalHost();>>> always returns the loopback address, which
    is 127.0.0.1. Why? Because in these recent distros, a system call of $ hostname always returns an address
    mapped onto the loopback device. Which causes ehcache's RMI Peer creation logic to always assign the loopback address, which causes the error you are seeing.

    All you need to do is crack open the network config and make sure that the hostname of the machine returns a valid network address accessible by other peers on the network.

*   I see log messages about SoftReferences. What are these about and how do I stop getting the messages?

    Ehcache uses SoftReferences with asynchronous RMI based replication, so that replicating caches do not run out of memory if the network
    is interrupted. Elements scheduled for replication will be collected instead. If this is happening, you will see warning messages from the
    replicator. It is also possible that a SoftReference can be reclaimed during the sending in which case you will see a debug level
    message in the receiving CachePeer.


    Some things you can do to fix them:

    * Set -Xms equal to -Xms. SoftReferences are also reclaimed in preference to increasing the heap size, which is a problem when an application
      is warming up.

    * Set the -Xmx to a high enough value so that SoftReferences do not get reclaimed.

    Having done the above, SoftReferences will then only be reclaimed if there is some interruption to replication and the message queue
      gets dangerously high.
   
*   My Hibernate Query caches entries are replicating but the other caches in the cluster are not using them.

    This is a Hibernate 3 bug. See http://opensource.atlassian.com/projects/hibernate/browse/HHH-3392 for tracking. It is fixed in 3.3.0.CR2 which was
    released in July 2008.


*   Active MQ Temporary Destinatons

    ActiveMQ seems to have a bug in at least ActiveMQ 5.1 where it does not cleanup temporary queues, even though they have been
    deleted. That bug appears to be long standing but was though to have been fixed.

    See:

    * http://www.nabble.com/Memory-Leak-Using-Temporary-Queues-td11218217.html#a11218217

    * http://issues.apache.org/activemq/browse/AMQ-1255

    The JMSCacheLoader uses temporary reply queues when loading. The Active MQ issue is readily reproduced in
    Ehcache integration testing. Accordingly, use of the JMSCacheLoader with ActiveMQ is not recommended. Open MQ
    tests fine.

*   Is Ehcache compatible with Google App Engine?

    Version 1.6 is compatible. See the {{{./googleappengine.html}Google App Engine Howto}}

*   Can my app server use JMS Replication?

    Some App Servers do not permit the creation of message listeners. This issue has been reported on Websphere 5.
    Websphere 4 did allow it. Tomcat allows it. Glassfish Allows it. Jetty allows it.

    Usually there is a way to turn off strict EJB compliance checks in your app server. See your vendor documentation.

*   Why does Ehcache 1.6 use more memory than 1.5?

    ConcurrentHashMap does not provide an eviction mechanism. We add that ourselves. For caches larger than 5000
    elements, we create an extra ArrayList equal to the size of the cache which holds keys. This can be an issue
    with larger keys. An optimisation which cache clients can use is:

---
    http://www.codeinstructions.com/2008/09/instance-pools-with-weakhashmap.html

    To reduce the number of key instances in memory to just one per logical
    key, all puts to the underlying ConcurrentHashMap could be replaced by
    map.put(pool.replace(key), value), as well as keyArray.set(index,
    pool.replace(key))

    You can take this approach when producing the keys before handing them over to EhCache.

---

    Even with this approach there is still some added overhead consumed by a reference consumed by each ArrayList element. 

     